Discours CTO : Industrialiser la Confiance avec LangSmith

PARTIE 1 : LE DISCOURS (√Ä lire ou adapter sur sc√®ne)

[Transition apr√®s la d√©mo du cas d'usage - Ton calme et assur√©]

¬´ Vous venez de voir ce dont notre architecture multi-agents est capable. Mais soyons honn√™tes entre professionnels : dans un environnement bancaire ultra-r√©glement√©, avec des donn√©es r√©parties sur 7 franchises op√©rationnelles diff√©rentes, r√©ussir la d√©mo du premier jour est la partie facile.

Le vrai d√©fi de l'entreprise, c'est le centi√®me jour. Comment prouver que notre syst√®me ne d√©rive pas ? Comment garantir qu'une mise √† jour de prompt ne va pas soudainement faire halluciner notre agent sur des donn√©es d'infrastructure critiques ?

C'est ici que LangSmith cesse d'√™tre un simple outil de d√©bogage pour devenir le c≈ìur de notre gouvernance : notre Usine d'Am√©lioration Continue.

[L'Annotation : La cr√©ation de la v√©rit√©]

Pour contr√¥ler l'IA, il nous faut une base de v√©rit√©. Chez nous, cette boucle commence par l'utilisateur final. Lorsqu'un agent donne une r√©ponse insatisfaisante, l'utilisateur nous envoie un simple signal : un pouce rouge.

Mais l'utilisateur ne corrige pas l'IA. Ce pouce rouge agit comme une alarme qui envoie automatiquement toute la trace technique de la conversation ‚Äî les requ√™tes, les appels d'API, les d√©cisions de routage ‚Äî dans ce que nous appelons l'Annotation Queue dans LangSmith.

C'est l√† que nos experts m√©tiers interviennent √† froid. Ils ouvrent LangSmith, autopsient la trace, et annotent manuellement la conversation. Ils √©crivent factuellement ce que l'agent aurait d√ª r√©pondre et quels outils il aurait d√ª appeler. Ce travail d'orf√®vre cr√©e notre Golden Dataset.

[Les 3 Piliers d'√âvaluation - √ânum√©rer clairement]

Une fois ce Dataset de r√©f√©rence cr√©√©, nous l'utilisons pour √©valuer automatiquement chaque nouvelle version de nos agents. Mais nous ne nous contentons pas d'un seul juge. Nous utilisons trois piliers d'√©valuation distincts pour auditer nos agents LangGraph :

D'abord, le LLM-as-a-Judge. C'est notre juge s√©mantique. Il lit la r√©ponse et √©value la Compl√©tude (a-t-on r√©pondu √† toute la question ?) et l'Hallucination (l'agent est-il rest√© fid√®le au contexte ?).

Ensuite, le Rule-Based Evaluator. Ici, pas d'IA, pas de probabilit√©s. C'est notre juge technique intraitable. Il utilise des r√®gles d'Exact Matching pour v√©rifier de mani√®re binaire qu'un num√©ro de ticket d'incident ou qu'un nom de serveur critique est bien pr√©sent au caract√®re pr√®s.

Enfin, et c'est crucial pour notre architecture f√©d√©r√©e : le Trajectory Evaluator. C'est l'auditeur de l'orchestration. Il ne lit pas le texte, il v√©rifie le chemin. L'agent a-t-il appel√© le bon outil d'investigation ? A-t-il interrog√© la base de donn√©es globale ou a-t-il fait l'effort de descendre dans les logs locaux ?

[Le Pilotage visuel : La Matrice de Confusion]

L'agr√©gation de ces milliers de scores quotidiens serait illisible sans un outil de pilotage. C'est pourquoi nous projetons tous ces r√©sultats d'√©valuation sur une Matrice de Confusion dans LangSmith, divis√©e en 4 quadrants.

L'administrateur peut voir imm√©diatement si nos ex√©cutions tombent dans la case Id√©al, Incomplet, √âchec, ou la plus dangereuse : la case Risqu√©.
Un cas "Risqu√©", c'est un agent qui a donn√© une r√©ponse tr√®s compl√®te et tr√®s bien formul√©e, mais qui contient une hallucination technique ind√©tectable par un utilisateur novice. Gr√¢ce √† LangSmith, on intercepte ces trajectoires, on les isole, et on corrige le tir avant que cela n'impacte la production.

[Conclusion : La Vision Neuro-Symbolique / Digital Twin - Plus d'intensit√©]

Aujourd'hui, cette usine d'√©valuation tourne √† plein r√©gime. Mais elle poss√®de une limite inh√©rente √† l'IT : l'obsolescence des datasets.

Dans une banque, l'infrastructure change chaque minute. Si notre √©quipe fige une r√©ponse de test statique aujourd'hui, elle sera fausse la semaine prochaine. L'√©valuateur p√©nalisera l'agent alors que l'architecture aura simplement √©volu√© !

Notre prochaine fronti√®re pour r√©gler cela, c'est l'int√©gration native de LangSmith avec notre Digital Twin ‚Äî notre Knowledge Graph d'entreprise propuls√© par TigerGraph.

Bient√¥t, nous n'aurons plus besoin de maintenir des milliers de r√©ponses "attendues" √©crites √† la main. Lors des campagnes de tests automatis√©es, nos juges n'iront plus lire un dataset statique p√©rim√©. Ils extrairont les affirmations techniques g√©n√©r√©es par l'agent (le c√¥t√© probabiliste) et les soumettront directement sous forme de requ√™tes √† notre Graphe (le c√¥t√© d√©terministe) pour faire du Fact-Checking en temps r√©el.

Le Graphe devient le correcteur automatique, incorruptible et toujours √† jour.

Nous couplons le moteur de raisonnement le plus agile du march√©, LangGraph, avec la source de v√©rit√© la plus d√©terministe qui soit, notre Digital Twin. Et c'est ainsi que nous passons de l'exp√©rimentation IA √† l'ing√©nierie bancaire.

Je vous remercie. ¬ª

PARTIE 2 : ANTIS√àCHES DU CTO (POUR LES Q&A)

Si quelqu'un dans le public (ou l'√©diteur LangChain) pose des questions pointues apr√®s la pr√©sentation, voici les r√©ponses "cl√©s en main" pour le CTO.

Q : "Qui fait l'annotation exactement ? Est-ce l'utilisateur final ?"

R√©ponse CTO : "Non, surtout pas. L'utilisateur final (le banquier, l'op√©rateur IT) se contente de donner un signal faible (un pouce rouge üëé). L'annotation lourde dans LangSmith est faite en diff√©r√© par nos Data Scientists ou nos Experts M√©tiers qui ouvrent la 'trace' d'ex√©cution pour comprendre pourquoi l'agent s'est tromp√©. C'est de l'autopsie chirurgicale."

Q : "Pourquoi avez-vous besoin d'un 'Trajectory Evaluator' si vous v√©rifiez d√©j√† la r√©ponse finale ?"

R√©ponse CTO : "Parce qu'avoir la bonne r√©ponse n'est pas suffisant si la m√©thode est mauvaise ou non s√©curis√©e. Notre architecture est un 'Syst√®me F√©d√©r√©'. Si l'agent trouve la bonne r√©ponse en appelant une API globale alors qu'il aurait d√ª utiliser un outil s√©curis√© d'investigation locale (Raw Data), c'est une faille d'architecture. La Trajectoire audite le respect de l'orchestration, pas juste le texte."

Q : "Vous parlez d'adosser LangSmith √† votre Knowledge Graph. Mais l'agent utilise d√©j√† le Graph pour r√©pondre via le RAG, non ? Quel est l'int√©r√™t de le requ√™ter √† nouveau pour l'√©valuation ?"

R√©ponse CTO : "C'est une question fondamentale. L'agent fait son RAG en production, oui. Mais lors de nos campagnes massives de tests de non-r√©gression (la nuit, par exemple), l'√©valuateur a besoin d'un 'Corrig√© Officiel' pour noter l'agent. Si ce corrig√© est un vieux dataset JSON √©crit √† la main il y a un mois, l'√©valuateur va punir l'agent car l'infrastructure aura chang√© entre-temps ! En connectant l'√©valuateur LangSmith au Graphe, notre 'Corrig√© Officiel' est dynamique et mis √† jour √† la seconde pr√®s. C'est la fin de l'obsolescence des tests."

Q : "Qu'est-ce que le quadrant 'Risqu√©' dans votre matrice de confusion ?"

R√©ponse CTO : "C'est le pire sc√©nario en IA : le mensonge convaincant. L'agent LangGraph a produit une r√©ponse tr√®s bien format√©e (bonne Compl√©tude), le LLM-Juge trouve √ßa tr√®s beau, mais factuellement, l'agent a invent√© un lien entre deux serveurs (Hallucination d√©tect√©e par notre Rule-Based ou notre Graphe). La matrice met ce cas en rouge clignotant."
