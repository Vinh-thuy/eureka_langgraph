# ğŸ§  Technical Design README â€“ Ã‰valuation de LightRAG vs RAG Classique

## 1. ğŸ¯ Contexte & Objectif

Dans le cadre du dÃ©veloppement de notre Digital Twin pour lâ€™infrastructure IT, nous cherchons Ã  amÃ©liorer les performances du systÃ¨me de question-rÃ©ponse sur documentation technique (ITSM, exploitation, Confluence, procÃ©dures incidents, etc.).

Ce PoC vise Ã  comparer **LightRAG** (graphe dynamique + reranking + vector search local) avec notre **approche RAG classique** (chunking statique + re-ranker + base vectorielle).

**Objectif** : DÃ©terminer si LightRAG permet une meilleure pertinence, rapiditÃ© de rÃ©ponse, traÃ§abilitÃ© ou interprÃ©tabilitÃ© que le RAG classique.

---

## 2. ğŸ§° Cas dâ€™usage cible

- Type de questions : *"Quel est le processus de rollback sur XYZ ?", "Quelles sont les Ã©tapes pour valider un change rÃ©seau ?"*
- Sources documentaires : fichiers Confluence exportÃ©s, procÃ©dures IT, playbooks internes, contrats de support.
- Contraintes : 
  - CohÃ©rence des rÃ©ponses (pas dâ€™hallucinations)
  - TraÃ§abilitÃ© des documents sources
  - RÃ©duction du temps de configuration

---

## 3. ğŸ” Solutions Ã©valuÃ©es

| CritÃ¨re                         | RAG Classique                      | LightRAG                             |
|----------------------------------|------------------------------------|--------------------------------------|
| Base vectorielle                | FAISS (persistÃ©e)                 | Local temporaire (in-memory)         |
| Reranking                       | ColBERT                           | reranking Graphe + ReAct             |
| Structuration de donnÃ©es        | Chunking linÃ©aire                 | Graphe orientÃ© contexte              |
| Pertinence                      | Moyenne (top 3 souvent bruitÃ©)    | Bonne (focus sur noeuds liÃ©s)        |
| InterprÃ©tabilitÃ© / logs         | LimitÃ©e                           | TrÃ¨s forte (graph des documents)     |
| FacilitÃ© dâ€™intÃ©gration          | Ã‰levÃ©e (langchain standard)       | Moyenne (custom repo, Ã  adapter)     |
| Temps de dÃ©veloppement          | Rapide                            | Moyen / Besoin dâ€™ingÃ©nierie          |
| ScalabilitÃ© / persistance       | Bonne                             | Ã€ industrialiser                     |

---

## 4. ğŸ§ª ImplÃ©mentation du PoC

ğŸ“ Dossiers :
- `/experiments/rag_classic/` â†’ pipeline avec FAISS + LangChain
- `/experiments/lightrag/` â†’ pipeline LightRAG avec graphe dynamique
- `/data/docs/` â†’ jeux de documents sources (extraits rÃ©els anonymisÃ©s)

Langages : Python 3.10  
LLM utilisÃ© : Mistral-Medium / GPT-4o (API)  
Evaluation : grille manuelle + test utilisateurs

---

## 5. ğŸ“Š RÃ©sultats & Benchmarks

### ğŸ”¹ Pertinence (sur 10 requÃªtes IT)
| MÃ©thode       | Moyenne score utilisateur /5 |
|---------------|-------------------------------|
| RAG Classique | 3.1                           |
| LightRAG      | 4.4                           |

### ğŸ”¹ Temps moyen de rÃ©ponse (sur corpus moyen)
| MÃ©thode       | Latence moyenne |
|---------------|-----------------|
| RAG Classique | 1.2s            |
| LightRAG      | 2.0s            |

### ğŸ”¹ TraÃ§abilitÃ© des sources
- RAG classique : sources visibles mais peu explicites
- LightRAG : graphe navigable par utilisateur, meilleures justifications

---

## 6. âœ… DÃ©cision & Justification

> **LightRAG est retenu** pour les cas dâ€™usage nÃ©cessitant :
> - Un haut niveau dâ€™interprÃ©tabilitÃ©
> - Une explicabilitÃ© forte (audit bancaire, traÃ§abilitÃ© documentaire)
> - Une sÃ©mantique fine dans des corpus flous (docs internes non standardisÃ©es)

> **RAG Classique est conservÃ©** pour :
> - Les cas simples, scalables ou Ã  fort besoin de performance
> - Les pipelines standardisÃ©s (tÃ¢ches gÃ©nÃ©riques, FAQ automatisÃ©e)

---

## 7. âš ï¸ Risques & Points Ouverts

- LightRAG nÃ©cessite :
  - Une phase de prÃ©-processing spÃ©cifique (relations inter-docs)
  - Une couche dâ€™industrialisation pour graphe persistant (TigerGraph ?)
- ComplexitÃ© dâ€™intÃ©gration avec notre pipeline infra actuel (ServiceNow / Dynatrace ?)

---

## 8. ğŸš€ Prochaines Ã‰tapes

- IntÃ©gration LightRAG dans notre agent Eureka (chatbot IT)
- Ã‰tude complÃ©mentaire sur la **persistance du graphe** (Neo4j vs TigerGraph)
- Ajout dâ€™un **semantic router** pour router RAG vs LightRAG en fonction de la requÃªte

---

## 9. ğŸ“ Annexes

- `notebooks/benchmark_results.ipynb` â†’ rÃ©sultats bruts
- `scripts/lightrag_graph_debug.py` â†’ visualisation du graphe
- Liens : [Repo LightRAG officiel](https://github.com/lightgraph-ai/lightrag)
