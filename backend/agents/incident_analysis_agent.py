from typing import TypedDict, List
import json
from pathlib import Path
from langgraph.graph import StateGraph, END, START
from langchain_core.messages import SystemMessage, HumanMessage

# 1. D√©finir l'√©tat de l'agent d'analyse d'incident
class IncidentAnalysisAgentState(TypedDict):
    question: str
    response: str
    final_response: str  # Synth√®se utilisateur ou r√©ponse finale
    conversation_context: dict  # Pour maintenir le contexte de conversation
    history: List[dict]  # Historique de la conversation
    end_conversation: bool  # Indique si la conversation est termin√©e
    intermediate_responses: List[dict]  # Pour stocker les r√©ponses interm√©diaires
    llm_context: dict  # Contexte enrichi pour le prompt syst√®me (cl√©)
    system_prompt: str  # Prompt syst√®me complet pour le LLM


# 2. D√©finir les fonctions utilitaires
def load_json_data(filename: str) -> dict:
    """Charge les donn√©es JSON depuis un fichier"""
    try:
        path = Path(__file__).parent.parent / 'data' / filename
        with open(path, 'r') as f:
            return json.load(f)
    except Exception as e:
        print(f"Erreur lors du chargement de {filename}: {e}")
        return {}


# 3. D√©finir les n≈ìuds du workflow
def map_incident_to_apps(state: IncidentAnalysisAgentState) -> dict:
    """√âtape 1: Mapper l'ID de l'incident aux codes d'application et enrichir le contexte partag√©."""
    print("--- √âTAPE 1: MAPPAGE INCIDENT -> APPLICATIONS ---")
    # Initialisation du contexte partag√©
    state.setdefault("llm_context", {})
    # Extraction de l'incident
    incident_id = state.get("conversation_context", {}).get("incident_id")
    if not incident_id:
        incident_digits = "".join(filter(str.isdigit, state['question']))
        incident_id = f"INC{incident_digits}" if incident_digits else "UNKNOWN"
    state["llm_context"]["incident_id"] = incident_id
    # Mapping incident -> applications
    incident_apps_mapping = load_json_data("incident_apps_mapping.json")
    app_codes = incident_apps_mapping.get(incident_id, [])
    state["llm_context"]["applications"] = [{"code": code} for code in app_codes]
    return state


def fetch_application_info(state: IncidentAnalysisAgentState) -> dict:
    """√âtape 2 : R√©cup√©rer les informations des applications et enrichir le contexte partag√©."""
    print("--- √âTAPE 2: R√âCUP√âRATION DES INFORMATIONS APPLICATIVES ---")
    app_dicts = state["llm_context"].get("applications", [])
    if not app_dicts:
        return state
    apps_data = load_json_data("applications_data.json")
    enriched_apps = []
    for app in app_dicts:
        code = app.get("code")
        info = apps_data.get(code, {})
        enriched_app = {"code": code}
        enriched_app.update(info)
        enriched_apps.append(enriched_app)
    state["llm_context"]["applications"] = enriched_apps
    return state


def display_application_info(state: IncidentAnalysisAgentState) -> dict:
    """√âtape 3: Afficher les informations de l'application (r√©ponse imm√©diate)"""
    print("--- √âTAPE 3: AFFICHAGE DES INFORMATIONS APPLICATIVES ---")
    
    app_info = state.get("app_info", {})
    incident_id = state.get("conversation_context", {}).get("incident_id", "INCONNU")
    
    # V√©rifier si la demande concerne les d√©tails d'une application sp√©cifique
    question = state.get("question", "").lower()
    if "d√©tails" in question and "application" in question:
        # Extraire le code d'application de la question si pr√©sent
        app_code = None
        for word in question.split():
            if word.upper().startswith("APP") and len(word) >= 4:  # Ex: APP001
                app_code = word.upper()
                break
        
        if app_code and app_code in app_info:
            # Afficher les d√©tails de l'application sp√©cifique
            info = app_info[app_code]
            response = {
                "type": "intermediate_response",
                "content": f"üîç D√©tails de l'application {info.get('name', 'Inconnue')} (Code: {app_code})\n\n"
                          f"- **Propri√©taire**: {info.get('owner', 'Non sp√©cifi√©')}\n"
                          f"- **Environnement**: {info.get('environment', 'Non sp√©cifi√©')}\n"
                          f"- **Version**: {info.get('version', 'Inconnue')}\n"
                          f"- **Statut**: {info.get('status', 'Inconnu')}\n"
                          f"- **Description**: {info.get('description', 'Aucune description disponible')}",
                "is_final": False
            }
            state["intermediate_responses"] = state.get("intermediate_responses", []) + [response]
            return state
    
    if not app_info:
        response = {
            "type": "intermediate_response",
            "content": f"‚ÑπÔ∏è Aucune information d'application trouv√©e pour l'incident {incident_id}.",
            "is_final": False
        }
    else:
        # Cr√©er un message utilisateur convivial
        app_list = "\n".join([f"- {info.get('name', 'Sans nom')} (Code: {code})" 
                              for code, info in app_info.items()])
        
        response = {
            "type": "intermediate_response",
            "content": f"üîç Incident {incident_id} - Applications concern√©es :\n{app_list}",
            "details": {
                "nombre_applications": len(app_info),
                "codes_applications": list(app_info.keys())
            },
            "is_final": False
        }
    
    # Ajouter la r√©ponse interm√©diaire
    state["intermediate_responses"] = state.get("intermediate_responses", []) + [response]
    
    return state

def find_related_incidents(state: IncidentAnalysisAgentState) -> dict:
    """√âtape 3: Trouver les incidents corr√©l√©s et enrichir le contexte partag√©."""
    print("--- √âTAPE 3: RECHERCHE D'INCIDENTS CORR√âL√âS ---")
    incident_id = state["llm_context"].get("incident_id")
    if not incident_id:
        state["llm_context"]["related_incidents"] = []
        return state
    related_incidents_data = load_json_data("related_incidents.json")
    related_incidents = related_incidents_data.get(incident_id, [])
    state["llm_context"]["related_incidents"] = related_incidents
    return state


def generate_system_prompt(llm_context: dict) -> str:
    """G√©n√®re un prompt syst√®me structur√© √† partir du contexte enrichi."""
    prompt = f"""
Vous √™tes un expert IT. Voici le contexte complet de l'incident :

Incident ID : {llm_context.get('incident_id', 'N/A')}

Applications concern√©es :
"""
    for app in llm_context.get('applications', []):
        prompt += f"- {app.get('code', '?')} : {app.get('name', '?')} (Propri√©taire : {app.get('owner', '?')})\n"
    prompt += "\nIncidents corr√©l√©s :\n"
    for inc in llm_context.get('related_incidents', []):
        prompt += f"- {inc.get('id', '?')} ({inc.get('status', '?')}) : {inc.get('description', '')}\n"
    prompt += "\nR√©pondez √† toute question de l‚Äôutilisateur en vous basant uniquement sur ce contexte."
    return prompt


def final_llm_node(state: IncidentAnalysisAgentState) -> dict:
    """
    Dernier n≈ìud : g√©n√®re :
    1. Un prompt syst√®me complet pour le LLM avec tout le contexte
    2. Une synth√®se utilisateur courte pour confirmer la disponibilit√© des donn√©es
    """
    print("--- √âTAPE FINALE : G√âN√âRATION DU PROMPT SYST√àME ---")
    llm_context = state.get("llm_context", {})
    
    # 1. G√©n√©rer le prompt complet pour le LLM
    system_prompt = generate_system_prompt(llm_context)
    state["system_prompt"] = system_prompt
    
    # 2. Cr√©er une synth√®se utilisateur courte
    incident_id = llm_context.get('incident_id', 'INCONNU')
    app_count = len(llm_context.get('applications', []))
    related_count = len(llm_context.get('related_incidents', []))
    
    summary = (
        f"‚úÖ Analyse pr√™te pour l'incident {incident_id}. "
        f"{app_count} application(s) concern√©e(s), {related_count} incident(s) corr√©l√©(s).\n\n"
        "Je peux maintenant r√©pondre √† vos questions sur cet incident.\n"
        "Exemples :\n"
        "- Quelle est l'application la plus critique ?\n"
        "- Affiche-moi les d√©tails de l'application APP001\n"
        "- Quels sont les incidents corr√©l√©s ?"
    )
    
    # D√©finir la r√©ponse finale avec la synth√®se
    state["final_response"] = summary
    
    return state


# 4. D√©finir le graphe de l'agent d'analyse d'incident
def create_incident_analysis_graph():
    # Cr√©er le graphe de workflow
    workflow = StateGraph(IncidentAnalysisAgentState)
    
    # Ajouter les n≈ìuds au graphe
    workflow.add_node("map_incident_to_apps", map_incident_to_apps)
    workflow.add_node("fetch_app_info", fetch_application_info)
    workflow.add_node("find_related_incidents", find_related_incidents)
    workflow.add_node("final_llm_node", final_llm_node)
    
    # D√©finir le flux de travail
    workflow.add_edge(START, "map_incident_to_apps")
    workflow.add_edge("map_incident_to_apps", "fetch_app_info")
    workflow.add_edge("fetch_app_info", "find_related_incidents")
    workflow.add_edge("find_related_incidents", "final_llm_node")
    workflow.add_edge("final_llm_node", END)
    
    # Compiler le workflow
    app = workflow.compile()
    
    # Fonction pour initialiser l'√©tat si n√©cessaire
    def _init_state(state):
        if not state.get("conversation_context"):
            state["conversation_context"] = {}
        if not state.get("history"):
            state["history"] = []
        if "response" not in state:
            state["response"] = ""
        if "final_response" not in state:
            state["final_response"] = ""
        if "end_conversation" not in state:
            state["end_conversation"] = False
        if "intermediate_responses" not in state:
            state["intermediate_responses"] = []
        if "llm_context" not in state:
            state["llm_context"] = {}
        return state
    
    # Envelopper la fonction invoke pour g√©rer l'initialisation
    original_invoke = app.invoke
    
    def wrapped_invoke(input_state):
        # Initialiser l'√©tat
        state = _init_state(input_state.copy())
        # Appeler la fonction originale
        return original_invoke(state)
    
    app.invoke = wrapped_invoke
    
    return app

